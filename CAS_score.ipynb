{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "from sklearn.metrics import f1_score,precision_recall_fscore_support\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    return (precision_macro, recall_macro, f1_macro), (precision_micro, recall_micro, f1_micro)\n",
    "\n",
    "marker = pd.read_csv('/data_path/marker.csv', index_col = 0)\n",
    "df = pd.read_csv(\"/data_path/data.csv\", index_col = 0)\n",
    "cell_type = pd.read_csv(\"/data_path/cell_type.csv\", index_col = 0)\n",
    "\n",
    "# Get real cell labels for calculating classification accuracy\n",
    "y_true = []\n",
    "adata_t_marker_nouk = sc.AnnData(df)\n",
    "dicts_cell_type = {}\n",
    "for index,value in enumerate(marker.index):\n",
    "    dicts_cell_type[value] = index\n",
    "temp = list(cell_type)\n",
    "for value in temp:\n",
    "    y_true.append(dicts_cell_type[value])\n",
    "\n",
    "\n",
    "adata_dense = adata_t_marker_nouk.X\n",
    "dict_gene_index = {}\n",
    "for index in range(len(adata_t_marker_nouk.var_names)):\n",
    "    dict_gene_index[adata_t_marker_nouk.var_names[index]] = index\n",
    "\n",
    "dicts_count = {}\n",
    "all_marker = []\n",
    "for index,value in enumerate(marker.index):\n",
    "    list_gene = []\n",
    "    for gene_index,gene in enumerate(marker.iloc[index]):\n",
    "        if gene == 1 and marker.columns[gene_index] in dict_gene_index:\n",
    "            list_gene.append(dict_gene_index[marker.columns[gene_index]])\n",
    "    dicts_count[dicts_cell_type[value]] = list_gene\n",
    "    all_marker = all_marker + list_gene\n",
    "\n",
    "marker_count = []\n",
    "dict_marker_count = {}\n",
    "for value in set(all_marker):\n",
    "    marker_count.append(all_marker.count(value))\n",
    "    dict_marker_count[value] = all_marker.count(value)\n",
    "\n",
    "list_count = []\n",
    "for index in range(len(adata_dense)):\n",
    "    temp_arr = np.zeros(len(dicts_count))\n",
    "    for key,value in dicts_count.items():\n",
    "        temp_weight = []\n",
    "        for ind,val in enumerate(value):\n",
    "            temp_weight.append(1-((dict_marker_count[val]-min(marker_count))/(max(marker_count)-min(marker_count)+1) ))\n",
    "        temp_weight = F.softmax(torch.from_numpy(np.array(temp_weight))).numpy()*len(temp_weight)\n",
    "        temp_arr[key] = (sum(adata_dense[index][value]*temp_weight)/(pow(len(value), 1/2)))\n",
    "    list_count.append(temp_arr)\n",
    "\n",
    "sim = F.softmax(torch.from_numpy(np.array(list_count)),dim=1)\n",
    "y_pred = torch.max(sim, dim=1)[1].numpy()\n",
    "\n",
    "# Get sctype score and based on this calculate Unique, Frequent and co-occurrence of Marker.\n",
    "\n",
    "dicts_weight = {}\n",
    "for key,values in dicts_count.items():\n",
    "    weight = []\n",
    "    for value in values:\n",
    "        wei1= sum(adata_dense[y_pred==key][:,value]>0)/(sum(adata_dense[:,value]>0))\n",
    "        wei2 = F.relu(torch.from_numpy(np.array(np.mean(adata_dense[y_pred==key][:,value]))))\n",
    "        wei3 = math.log10(torch.from_numpy(np.array(len(adata_dense)/(sum(adata_dense[:,value]>0)))))\n",
    "    dicts_weight[key] = weight\n",
    "\n",
    "list_count = []\n",
    "for index in range(len(adata_dense)):\n",
    "    temp_arr = np.zeros(len(dicts_count))\n",
    "    for indexs,value in dicts_count.items():\n",
    "        temp_weight = []\n",
    "        temp_weight_2 = []\n",
    "        for ind,val in enumerate(value):\n",
    "            temp_weight.append(dicts_weight[indexs][ind])\n",
    "            temp_weight_2.append(1-((dict_marker_count[val]-min(marker_count))/(max(marker_count)-min(marker_count)+1)))\n",
    "        new_weight = temp_weight*np.array(temp_weight_2)\n",
    "        new_weight = F.softmax(torch.from_numpy(new_weight)).numpy()*len(new_weight)\n",
    "        temp_arr[indexs] = sum(new_weight*adata_dense[index][value])/(pow(len(new_weight), 1/2))\n",
    "    list_count.append(temp_arr)\n",
    "\n",
    "sim = torch.from_numpy(np.array(list_count))\n",
    "y_pred = torch.max(sim, dim=1)[1].numpy()\n",
    "y_soft = F.softmax(sim,dim=1).numpy()\n",
    "(precision_macro, recall_macro, f1_macro), (precision_micro, recall_micro, f1_micro)= np.round(f1(np.array(y_true), np.array(y_pred)), 5)\n",
    "print('F1 score: f1_macro = {}, f1_micro = {}'.format(f1_macro, f1_micro))\n",
    "print('precision score: precision_macro = {}, precision_micro = {}'.format(precision_macro, precision_micro))\n",
    "print('recall score: recall_macro = {}, recall_micro = {}'.format(recall_macro, recall_micro))\n",
    "\n",
    "adata_t_marker_nouk.obs[\"broad_cell_type\"] = y_true\n",
    "adata_t_marker_nouk.uns[\"Celltype_soft\"] = y_soft\n",
    "adata_t_marker_nouk.uns[\"dicts_cell_type\"] = dicts_cell_type\n",
    "adata_t_marker_nouk.obs[\"y_pred\"] = y_pred\n",
    "\n",
    "adata_t_marker_nouk.write(\"/data_path/data_CAS.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f560ba1c49e42bec68e292d0902545032636bb161d9766ccb136eadbc91b621"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
